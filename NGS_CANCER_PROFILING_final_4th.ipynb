{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00892bc1-1591-4dc2-84b1-b6e797651d05",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Setting Up NGS Platform and Configuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "907b6687-f0af-4125-a0e6-dec4a41a3ed4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python interpreter will be restarted.\nCollecting BIo\n  Downloading bio-1.5.9-py3-none-any.whl (276 kB)\nCollecting gprofiler-official\n  Downloading gprofiler_official-1.0.0-py3-none-any.whl (9.3 kB)\nCollecting pooch\n  Downloading pooch-1.7.0-py3-none-any.whl (60 kB)\nCollecting biopython>=1.80\n  Downloading biopython-1.81-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\nRequirement already satisfied: pandas in /databricks/python3/lib/python3.9/site-packages (from BIo) (1.4.2)\nCollecting tqdm\n  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\nRequirement already satisfied: requests in /databricks/python3/lib/python3.9/site-packages (from BIo) (2.27.1)\nCollecting mygene\n  Downloading mygene-3.2.2-py2.py3-none-any.whl (5.4 kB)\nRequirement already satisfied: numpy in /databricks/python3/lib/python3.9/site-packages (from biopython>=1.80->BIo) (1.21.5)\nCollecting biothings-client>=0.2.6\n  Downloading biothings_client-0.3.0-py2.py3-none-any.whl (29 kB)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.9/site-packages (from requests->BIo) (3.3)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /databricks/python3/lib/python3.9/site-packages (from requests->BIo) (2.0.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.9/site-packages (from requests->BIo) (1.26.9)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.9/site-packages (from requests->BIo) (2021.10.8)\nRequirement already satisfied: python-dateutil>=2.8.1 in /databricks/python3/lib/python3.9/site-packages (from pandas->BIo) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.9/site-packages (from pandas->BIo) (2021.3)\nRequirement already satisfied: six>=1.5 in /databricks/python3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->BIo) (1.16.0)\nRequirement already satisfied: packaging>=20.0 in /databricks/python3/lib/python3.9/site-packages (from pooch->BIo) (21.3)\nRequirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.9/dist-packages (from pooch->BIo) (2.6.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /databricks/python3/lib/python3.9/site-packages (from packaging>=20.0->pooch->BIo) (3.0.4)\nInstalling collected packages: biothings-client, tqdm, pooch, mygene, gprofiler-official, biopython, BIo\nSuccessfully installed BIo-1.5.9 biopython-1.81 biothings-client-0.3.0 gprofiler-official-1.0.0 mygene-3.2.2 pooch-1.7.0 tqdm-4.65.0\nPython interpreter will be restarted.\n"
     ]
    }
   ],
   "source": [
    "pip install BIo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2fe5462-cb7a-442c-b335-3e7812143163",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from Bio import SeqIO\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3cb915d0-c148-42da-bd79-fc86ec0bfa19",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.conf.set(f\"fs.azure.sas.raw.ngddatacancerprofiling.blob.core.windows.net\",'?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupiytfx&se=2023-08-04T01:56:38Z&st=2023-08-03T17:56:38Z&spr=https&sig=VqJDiNMv2jVQiKpLtkI82Bgf4cAeKAAfZ943kI5GyOQ%3D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "753b1a1f-ad9e-4345-9158-50708a240d2a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[3]: [FileInfo(path='wasbs://raw@ngddatacancerprofiling.blob.core.windows.net/ERR10360601_1.fastq', name='ERR10360601_1.fastq', size=10154765124, modificationTime=1690958599000),\n FileInfo(path='wasbs://raw@ngddatacancerprofiling.blob.core.windows.net/ERR10360601_2.fastq', name='ERR10360601_2.fastq', size=10154765124, modificationTime=1690959737000),\n FileInfo(path='wasbs://raw@ngddatacancerprofiling.blob.core.windows.net/GCF_000001405.40_GRCh38.p14_genomic.fna', name='GCF_000001405.40_GRCh38.p14_genomic.fna', size=3339739109, modificationTime=1690957252000),\n FileInfo(path='wasbs://raw@ngddatacancerprofiling.blob.core.windows.net/bowtie-1.3.1-macos-x86_64/', name='bowtie-1.3.1-macos-x86_64/', size=0, modificationTime=0),\n FileInfo(path='wasbs://raw@ngddatacancerprofiling.blob.core.windows.net/ouput/', name='ouput/', size=0, modificationTime=0),\n FileInfo(path='wasbs://raw@ngddatacancerprofiling.blob.core.windows.net/partaa.fastq', name='partaa.fastq', size=705555584, modificationTime=1690993295000),\n FileInfo(path='wasbs://raw@ngddatacancerprofiling.blob.core.windows.net/test_ngs.fastq', name='test_ngs.fastq', size=3660, modificationTime=1690951468000)]"
     ]
    }
   ],
   "source": [
    "dbutils.fs.ls('wasbs://raw@ngddatacancerprofiling.blob.core.windows.net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac2224c5-8a66-430a-b5f8-442c75696d61",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# dbutils.fs.mount(\n",
    "#   source='wasbs://raw@ngddatacancerprofiling.blob.core.windows.net',\n",
    "#   mount_point='/mnt/raw',\n",
    "#   extra_configs={'fs.azure.account.key.ngddatacancerprofiling.blob.core.windows.net':'Wu6/hgfQirWHysHsOwD3mbj7Jl0ewxFyd0E6pfKD5gqZfbhQictzDGRw4IzDY/crFiuh6wRcBAV8+AStmN7i9Q=='}\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "64c2a9a3-9ab3-47e7-a490-0c8fe36468e4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Reading cancer Fastq files and Reference genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d806626-72d5-4f11-9603-b4d4461a4a39",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def read_fastq_as_rdd_and_dataframe(file_path):\n",
    "    # Create a SparkSession\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"FASTQ Reader\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "    # Read FASTQ file using Biopython\n",
    "    fastq_records = SeqIO.parse(file_path, \"fastq\")\n",
    "    # for record in fastq_records:\n",
    "    #     print(\"ID:\", record.id)\n",
    "    #     print(\"Sequence:\", record.seq)\n",
    "    #     print(\"Quality:\", record.letter_annotations[\"phred_quality\"])\n",
    "    #     print(\"---\")\n",
    "    record_dicts = []\n",
    "    for record in fastq_records:\n",
    "        record_dict = {\n",
    "            \"id\": record.id,\n",
    "            \"sequence\": str(record.seq),\n",
    "            \"quality\": str(record.letter_annotations[\"phred_quality\"])\n",
    "        }\n",
    "        record_dicts.append(record_dict)\n",
    "    # print(record_dicts)\n",
    "    # Create an RDD from the list of dictionaries\n",
    "    rdd = spark.sparkContext.parallelize(record_dicts)\n",
    "    # rdd.take(5).foreach(print)\n",
    "    # Convert RDD to DataFrame\n",
    "    # df = rdd.map(lambda x: Row(**x)).toDF()\n",
    "    return rdd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12e94ca6-c91a-4427-804e-111e8db0bb3b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# file_path = \"/dbfs/mnt/raw/test_ngs.fastq\"\n",
    "# # file_path='wasbs://raw@ngddatacancerprofiling.blob.core.windows.net/test_ngs.fastq'\n",
    "# cancer_rdd=read_fastq_as_rdd_and_dataframe(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3567786f-493e-46f8-8b80-394212633468",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# for row in cancer_rdd.collect():\n",
    "#     print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d0ace42-8ea5-48b6-84d0-dfcdaa9f23f5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df=cancer_rdd.map(lambda x: Row(**x)).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2479328f-b50a-4678-9c15-f59303fd1397",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3151fdd-67b2-41b5-a352-6d4e82510187",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "file_path = \"/dbfs/mnt/raw/partaa.fastq\"\n",
    "# file_path='wasbs://raw@ngddatacancerprofiling.blob.core.windows.net/test_ngs.fastq'\n",
    "cancer_rdd=read_fastq_as_rdd_and_dataframe(file_path)\n",
    "df_cancer=cancer_rdd.map(lambda x: Row(**x)).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b625d036-779f-4ffe-8669-d78e9aefb72e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# for row in cancer_rdd.collect():\n",
    "#     print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "afa3fd0e-51bc-461f-9fdf-25b0866947c8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+--------------------+\n|            id|            sequence|             quality|\n+--------------+--------------------+--------------------+\n| ERR10360601.1|CACCCCTGAAGCTGCAC...|[37, 37, 37, 37, ...|\n| ERR10360601.2|CTTGCATTTTACAGGGG...|[37, 37, 37, 37, ...|\n| ERR10360601.3|TGATGGAACATGCTGGT...|[37, 37, 37, 37, ...|\n| ERR10360601.4|CCCTTAGTTTCATCATT...|[37, 25, 37, 37, ...|\n| ERR10360601.5|TTTCTCTTTCACTCGAG...|[25, 37, 37, 37, ...|\n| ERR10360601.6|GACAGTTTCAGTAAAGT...|[37, 37, 37, 37, ...|\n| ERR10360601.7|TGATAGACTCTGGGGTA...|[37, 37, 37, 37, ...|\n| ERR10360601.8|GAAAAATTAACTTTATC...|[37, 37, 37, 37, ...|\n| ERR10360601.9|GTCTCCTGACCAGTGGT...|[37, 37, 37, 37, ...|\n|ERR10360601.10|GATGAAGTCAATACAAC...|[37, 37, 37, 37, ...|\n|ERR10360601.11|TTAATGTTAGTATTTTT...|[37, 37, 37, 37, ...|\n|ERR10360601.12|GACAGATATTATTAAAA...|[37, 37, 37, 37, ...|\n|ERR10360601.13|TAATACATTCTTCCTTC...|[37, 37, 25, 37, ...|\n|ERR10360601.14|TAATAGTATTCCTGTGA...|[37, 37, 37, 37, ...|\n|ERR10360601.15|CCATACACGCCAGCAAC...|[37, 37, 37, 37, ...|\n|ERR10360601.16|GGAACTGTCTGCAATGG...|[37, 37, 37, 37, ...|\n|ERR10360601.17|TTTAAATTTTTTTGAGC...|[37, 37, 37, 37, ...|\n|ERR10360601.18|TTAAATTAGGGGAGCTG...|[37, 37, 37, 37, ...|\n|ERR10360601.19|TCTAAATTCCATTTTTG...|[37, 37, 37, 37, ...|\n|ERR10360601.20|TGCAATTTCTGATGTGT...|[37, 37, 37, 37, ...|\n+--------------+--------------------+--------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# df_cancer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92f1344c-5d7e-4668-b76c-412881b8ff34",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[9]: 2500000"
     ]
    }
   ],
   "source": [
    "# df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7700c31b-c68f-4ff6-a287-ffaf61353f06",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Configure Spark\n",
    "spark = SparkSession.builder \\\n",
    "        .appName(\"FASTQ Reader\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "# Replace 'file:///path/to/your/GCF_000001405.40_GRCh38.p14_genomic.fna' with the actual file path\n",
    "genome_file_path = '/mnt/raw/GCF_000001405.40_GRCh38.p14_genomic.fna'\n",
    "\n",
    "# Load the genome file into an RDD\n",
    "genome_rdd = spark.read.text(genome_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f40acef-ae61-4b16-b70f-8a4d853431ba",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# genome_rdd,df\n",
    "\n",
    "# bam_df = fastq_df.join(reference_genome_df, on=\"sequence\")\n",
    "\n",
    "# bam_df = df.join(genome_rdd,df, on=\"sequence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b3c66c6-be07-43f1-b758-c2ffca6e1c4d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# genome_rdd.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e30c93f-b385-4b15-a458-4cb177a30bdf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[11]: 41231443"
     ]
    }
   ],
   "source": [
    "# genome_rdd.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "09e5cc23-61a7-4a4d-9880-f3c2b89d1d49",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Cleaning of Dataframe created from reference genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c61729f2-ccff-4ae6-b630-86851a29840b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"Cleaning Reference Genome\").getOrCreate()\n",
    "\n",
    "# Load the reference genome\n",
    "reference_genome_df = spark.read.format(\"fasta\").load(\"data/reference_genome.fasta\")\n",
    "\n",
    "# Remove repetitive sequences\n",
    "repetitive_sequences = reference_genome_df.filter(reference_genome_df[\"sequence\"].rlike(\"N+\"))\n",
    "reference_genome_df = reference_genome_df.subtract(repetitive_sequences)\n",
    "\n",
    "# Remove low-quality sequences\n",
    "low_quality_sequences = reference_genome_df.filter(reference_genome_df[\"quality\"].lt(20))\n",
    "reference_genome_df = reference_genome_df.subtract(low_quality_sequences)\n",
    "\n",
    "# Trim adapters\n",
    "adapters = reference_genome_df.filter(reference_genome_df[\"sequence\"].startswith(\"AGATCGGAAGAGCACACGTC\"))\n",
    "reference_genome_df = reference_genome_df.subtract(adapters)\n",
    "\n",
    "# Fill gaps\n",
    "gaps = reference_genome_df.filter(reference_genome_df[\"sequence\"].contains(\"-\"))\n",
    "reference_genome_df = reference_genome_df.subtract(gaps)\n",
    "\n",
    "# Save the cleaned reference genome\n",
    "reference_genome_df.write.save(\"data/cleaned_reference_genome.fasta\", format=\"fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13fafe22-1974-434c-a40e-463ef2297a99",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# genome_rdd['value']=genome_rdd['value'].apply(str.upper)\n",
    "# import pyspark.sql.functions as F\n",
    "\n",
    "# df_reference=genome_rdd.select(F.upper(genome_rdd.value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e195e6a-f1fe-47f8-a27a-a4a81896bf42",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "genome_path = '/mnt/raw/GCF_000001405.40_GRCh38.p14_genomic.fna'\n",
    "fastq_path = '/mnt/raw/ERR10360601_1.fastq'\n",
    "\n",
    "# Load FASTQ data as DataFrame (assuming it's in FASTQ format)\n",
    "fastq_df = spark.read.format('fastq').load(fastq_path)\n",
    "\n",
    "# Load reference genome as RDD (assuming it's in FASTA format)\n",
    "genome_rdd = spark.sparkContext.textFile(genome_path)\n",
    "\n",
    "# Step 3: Preprocess the data (optional)\n",
    "# Perform preprocessing steps as required, e.g., quality filtering, adapter trimming, etc.\n",
    "# You can use PySpark functions or external tools for this step.\n",
    "\n",
    "# Step 4: Perform read alignment using an external aligner (e.g., Bowtie, BWA, or HISAT2)\n",
    "# Use Python's subprocess module to call the aligner from the shell\n",
    "import subprocess\n",
    "\n",
    "# Replace 'path/to/aligner' with the actual path to the aligner binary on Databricks\n",
    "# Replace 'path/to/output' with the desired output path for alignment results (SAM/BAM file)\n",
    "aligner_command = ['/dbfs/mnt/raw', '--options', genome_path, fastq_path, '-S', '/dbfs/mnt/raw']\n",
    "subprocess.run(aligner_command, shell=True)\n",
    "\n",
    "# Step 5: Process and analyze the alignment results\n",
    "# Load the alignment results (SAM/BAM file) into a DataFrame (assuming it's in SAM format)\n",
    "alignment_results_path = '/dbfs/path/to/output'\n",
    "alignment_df = spark.read.format('sam').load(alignment_results_path)\n",
    "\n",
    "# Perform any necessary processing and analysis on the alignment DataFrame\n",
    "# For example, count mapped reads, calculate alignment quality scores, etc.\n",
    "\n",
    "# Display or save the results as required\n",
    "alignment_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7924965-56f0-4e58-8899-390cedc5c188",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n|        upper(value)|\n+--------------------+\n|>NC_000001.11 HOM...|\n|NNNNNNNNNNNNNNNNN...|\n|NNNNNNNNNNNNNNNNN...|\n|NNNNNNNNNNNNNNNNN...|\n|NNNNNNNNNNNNNNNNN...|\n|NNNNNNNNNNNNNNNNN...|\n|NNNNNNNNNNNNNNNNN...|\n|NNNNNNNNNNNNNNNNN...|\n|NNNNNNNNNNNNNNNNN...|\n|NNNNNNNNNNNNNNNNN...|\n|NNNNNNNNNNNNNNNNN...|\n|NNNNNNNNNNNNNNNNN...|\n|NNNNNNNNNNNNNNNNN...|\n|NNNNNNNNNNNNNNNNN...|\n|NNNNNNNNNNNNNNNNN...|\n|NNNNNNNNNNNNNNNNN...|\n|NNNNNNNNNNNNNNNNN...|\n|NNNNNNNNNNNNNNNNN...|\n|NNNNNNNNNNNNNNNNN...|\n|NNNNNNNNNNNNNNNNN...|\n+--------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df_reference.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "70b8a3a9-2203-4948-89dc-2c95522aa1e4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_cancer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7cc4785-43b6-4444-b6f6-9782b3c40db0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[6]: 41231443"
     ]
    }
   ],
   "source": [
    "df_reference.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e7c682a-7579-48ef-bed0-a2244706dcb1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[27]: 2500000"
     ]
    }
   ],
   "source": [
    "df_cancer.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee013856-2a3e-4a86-ac51-664b1ff60df7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "repetitive_sequences = df_reference.filter(df_reference[\"upper(value)\"].rlike(\"N\"))\n",
    "reference_genome_df = df_reference.subtract(repetitive_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6cf434bb-82d1-4f81-8dd9-c22d8742cde4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[10]: 38519708"
     ]
    }
   ],
   "source": [
    "reference_genome_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b6b3129-59e2-4655-aec7-c66af43e9b3e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n|        upper(value)|\n+--------------------+\n|AGCCAGGTTACCTTGTC...|\n|CAGTTAGGAAAAGAGGA...|\n|GCTCCAAGGAGGGTCCG...|\n|CACATATGTTAATGTTT...|\n|TACTACTGCTTTTAATA...|\n|ATTTTTATATCACATGA...|\n|TGCCTATCAAGTATCTA...|\n|CATACCTGTTAGAATGG...|\n|GTGTGTAGTCCTAGCTA...|\n|CATGCACACCGTCACAC...|\n|GTACACTCCCTCACCTT...|\n|GTAGTATTAGTGGTGTT...|\n|CAGGTATGTTTATTGCA...|\n|TGCATATATTTTGTGGT...|\n|TCTCTGCGGTGAGGCAG...|\n|AAAGCCCTGAACTGAGA...|\n|TGAGGTCAGCAGTTCAA...|\n|CAGTTCTCAAGATTTTA...|\n|TTTGAAAAACAAACAAC...|\n|CGATCTCAGCTCACTGC...|\n+--------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "reference_genome_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fba065aa-3d91-4699-a34d-1d9897e97710",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+--------------------+\n|            id|            sequence|             quality|\n+--------------+--------------------+--------------------+\n| ERR10360601.1|CACCCCTGAAGCTGCAC...|[37, 37, 37, 37, ...|\n| ERR10360601.2|CTTGCATTTTACAGGGG...|[37, 37, 37, 37, ...|\n| ERR10360601.3|TGATGGAACATGCTGGT...|[37, 37, 37, 37, ...|\n| ERR10360601.4|CCCTTAGTTTCATCATT...|[37, 25, 37, 37, ...|\n| ERR10360601.5|TTTCTCTTTCACTCGAG...|[25, 37, 37, 37, ...|\n| ERR10360601.6|GACAGTTTCAGTAAAGT...|[37, 37, 37, 37, ...|\n| ERR10360601.7|TGATAGACTCTGGGGTA...|[37, 37, 37, 37, ...|\n| ERR10360601.8|GAAAAATTAACTTTATC...|[37, 37, 37, 37, ...|\n| ERR10360601.9|GTCTCCTGACCAGTGGT...|[37, 37, 37, 37, ...|\n|ERR10360601.10|GATGAAGTCAATACAAC...|[37, 37, 37, 37, ...|\n|ERR10360601.11|TTAATGTTAGTATTTTT...|[37, 37, 37, 37, ...|\n|ERR10360601.12|GACAGATATTATTAAAA...|[37, 37, 37, 37, ...|\n|ERR10360601.13|TAATACATTCTTCCTTC...|[37, 37, 25, 37, ...|\n|ERR10360601.14|TAATAGTATTCCTGTGA...|[37, 37, 37, 37, ...|\n|ERR10360601.15|CCATACACGCCAGCAAC...|[37, 37, 37, 37, ...|\n|ERR10360601.16|GGAACTGTCTGCAATGG...|[37, 37, 37, 37, ...|\n|ERR10360601.17|TTTAAATTTTTTTGAGC...|[37, 37, 37, 37, ...|\n|ERR10360601.18|TTAAATTAGGGGAGCTG...|[37, 37, 37, 37, ...|\n|ERR10360601.19|TCTAAATTCCATTTTTG...|[37, 37, 37, 37, ...|\n|ERR10360601.20|TGCAATTTCTGATGTGT...|[37, 37, 37, 37, ...|\n+--------------+--------------------+--------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df_cancer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e59c440-9dfe-43ce-8f53-29f6447e664c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python interpreter will be restarted.\nRequirement already satisfied: subprocess.run in /local_disk0/.ephemeral_nfs/envs/pythonEnv-451acd1f-09cb-48cb-a29a-f7dec7a7049e/lib/python3.9/site-packages (0.0.8)\nPython interpreter will be restarted.\n"
     ]
    }
   ],
   "source": [
    "pip install subprocess.run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee93224f-9d24-43cd-b379-fd51d01d39e1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#  Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "904678b1-7563-47a8-a3fc-194eb27c4d30",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abf29551-4236-4b3e-82b1-c7254aab67fa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "genome_path = '/mnt/raw/GCF_000001405.40_GRCh38.p14_genomic.fna'\n",
    "fastq_path = '/mnt/raw/partaa.fastq'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c5253cb-578a-45db-9d89-13f9593002a2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[4]: CompletedProcess(args=['/dbfs/mnt/raw/bowtie-1.3.1-macos-x86_64/bowtie', '--options', '/mnt/raw/GCF_000001405.40_GRCh38.p14_genomic.fna', '/mnt/raw/partaa.fastq', '-S', '/dbfs/mnt/raw/output'], returncode=1)"
     ]
    }
   ],
   "source": [
    "aligner_command = ['/dbfs/mnt/raw/bowtie-1.3.1-macos-x86_64/bowtie', '--options', genome_path, fastq_path, '-S', '/dbfs/mnt/raw/output']\n",
    "subprocess.run(aligner_command, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8b2f925e-d67a-481a-bc59-d5cb7042b71c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Variant Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba7c74e6-709e-4f83-8259-d8ab4f8d0aa2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python interpreter will be restarted.\nCollecting hail\n  Downloading hail-0.2.120-py3-none-any.whl (141.6 MB)\nCollecting azure-storage-blob<13,>=12.11.0\n  Downloading azure_storage_blob-12.17.0-py3-none-any.whl (388 kB)\nCollecting Deprecated<1.3,>=1.2.10\n  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\nCollecting janus<1.1,>=0.6\n  Downloading janus-1.0.0-py3-none-any.whl (6.9 kB)\nCollecting typer<1,>=0.9.0\n  Downloading typer-0.9.0-py3-none-any.whl (45 kB)\nCollecting humanize<2,>=1.0.0\n  Downloading humanize-1.1.0-py3-none-any.whl (52 kB)\nCollecting python-json-logger<3,>=2.0.2\n  Downloading python_json_logger-2.0.7-py3-none-any.whl (8.1 kB)\nCollecting jproperties<3,>=2.1.1\n  Downloading jproperties-2.1.1-py2.py3-none-any.whl (17 kB)\nRequirement already satisfied: botocore<2.0,>=1.20 in /databricks/python3/lib/python3.9/site-packages (from hail) (1.24.32)\nCollecting orjson<4,>=3.6.4\n  Downloading orjson-3.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\nCollecting azure-identity<2,>=1.6.0\n  Downloading azure_identity-1.13.0-py3-none-any.whl (151 kB)\nCollecting aiohttp<4,>=3.8.1\n  Downloading aiohttp-3.8.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\nCollecting uvloop<1,>=0.16.0\n  Downloading uvloop-0.17.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.2 MB)\nCollecting protobuf==3.20.2\n  Downloading protobuf-3.20.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\nCollecting google-auth<3,>=2.14.1\n  Downloading google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\nRequirement already satisfied: numpy<2 in /databricks/python3/lib/python3.9/site-packages (from hail) (1.21.5)\nRequirement already satisfied: requests<3,>=2.25.1 in /databricks/python3/lib/python3.9/site-packages (from hail) (2.27.1)\nRequirement already satisfied: plotly<6,>=5.5.0 in /databricks/python3/lib/python3.9/site-packages (from hail) (5.6.0)\nCollecting azure-mgmt-storage==20.1.0\n  Downloading azure_mgmt_storage-20.1.0-py3-none-any.whl (2.3 MB)\nCollecting sortedcontainers<3,>=2.4.0\n  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\nCollecting frozenlist<2,>=1.3.1\n  Downloading frozenlist-1.4.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (228 kB)\nCollecting hurry.filesize<1,>=0.9\n  Downloading hurry.filesize-0.9.tar.gz (2.8 kB)\nCollecting asyncinit<0.3,>=0.2.4\n  Downloading asyncinit-0.2.4-py3-none-any.whl (2.8 kB)\nCollecting google-cloud-storage>=1.25.0\n  Downloading google_cloud_storage-2.10.0-py2.py3-none-any.whl (114 kB)\nRequirement already satisfied: nest-asyncio<2,>=1.5.4 in /databricks/python3/lib/python3.9/site-packages (from hail) (1.5.5)\nRequirement already satisfied: scipy<1.10,>1.2 in /databricks/python3/lib/python3.9/site-packages (from hail) (1.7.3)\nCollecting rich==12.6.0\n  Downloading rich-12.6.0-py3-none-any.whl (237 kB)\nCollecting dill<0.4,>=0.3.1.1\n  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\nCollecting aiodns<3,>=2.0.0\n  Downloading aiodns-2.0.0-py2.py3-none-any.whl (4.8 kB)\nCollecting tabulate<1,>=0.8.9\n  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\nCollecting bokeh<4,>=3\n  Downloading bokeh-3.2.1-py3-none-any.whl (7.8 MB)\nCollecting parsimonious<1\n  Downloading parsimonious-0.10.0-py3-none-any.whl (48 kB)\nCollecting decorator<5\n  Downloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\nCollecting pandas<3,>=2\n  Downloading pandas-2.0.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\nCollecting pyspark<3.4,>=3.3.0\n  Downloading pyspark-3.3.2.tar.gz (281.4 MB)\nCollecting avro<1.12,>=1.10\n  Downloading avro-1.11.2.tar.gz (85 kB)\n  Installing build dependencies: started\n  Installing build dependencies: finished with status 'done'\n  Getting requirements to build wheel: started\n  Getting requirements to build wheel: finished with status 'done'\n    Preparing wheel metadata: started\n    Preparing wheel metadata: finished with status 'done'\nRequirement already satisfied: boto3<2.0,>=1.17 in /databricks/python3/lib/python3.9/site-packages (from hail) (1.21.32)\nCollecting pyyaml<7.0,>=6.0\n  Downloading PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (738 kB)\nCollecting azure-mgmt-core<2.0.0,>=1.3.1\n  Downloading azure_mgmt_core-1.4.0-py3-none-any.whl (27 kB)\nCollecting azure-common~=1.1\n  Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\nCollecting msrest>=0.6.21\n  Downloading msrest-0.7.1-py3-none-any.whl (85 kB)\nCollecting commonmark<0.10.0,>=0.9.0\n  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\nRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /databricks/python3/lib/python3.9/site-packages (from rich==12.6.0->hail) (2.11.2)\nCollecting pycares>=3.0.0\n  Downloading pycares-4.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /databricks/python3/lib/python3.9/site-packages (from aiohttp<4,>=3.8.1->hail) (2.0.4)\nCollecting yarl<2.0,>=1.0\n  Downloading yarl-1.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (269 kB)\nCollecting async-timeout<5.0,>=4.0.0a3\n  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\nCollecting aiosignal>=1.1.2\n  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\nCollecting multidict<7.0,>=4.5\n  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\nRequirement already satisfied: attrs>=17.3.0 in /databricks/python3/lib/python3.9/site-packages (from aiohttp<4,>=3.8.1->hail) (21.4.0)\nRequirement already satisfied: six>=1.12.0 in /databricks/python3/lib/python3.9/site-packages (from azure-identity<2,>=1.6.0->hail) (1.16.0)\nCollecting msal-extensions<2.0.0,>=0.3.0\n  Downloading msal_extensions-1.0.0-py2.py3-none-any.whl (19 kB)\nCollecting msal<2.0.0,>=1.20.0\n  Downloading msal-1.23.0-py2.py3-none-any.whl (90 kB)\nCollecting azure-core<2.0.0,>=1.11.0\n  Downloading azure_core-1.28.0-py3-none-any.whl (185 kB)\nRequirement already satisfied: cryptography>=2.5 in /databricks/python3/lib/python3.9/site-packages (from azure-identity<2,>=1.6.0->hail) (3.4.8)\nCollecting typing-extensions>=4.3.0\n  Downloading typing_extensions-4.7.1-py3-none-any.whl (33 kB)\nCollecting isodate>=0.6.1\n  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\nCollecting contourpy>=1\n  Downloading contourpy-1.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\nRequirement already satisfied: Jinja2>=2.9 in /databricks/python3/lib/python3.9/site-packages (from bokeh<4,>=3->hail) (2.11.3)\nCollecting xyzservices>=2021.09.1\n  Downloading xyzservices-2023.7.0-py3-none-any.whl (56 kB)\nRequirement already satisfied: tornado>=5.1 in /databricks/python3/lib/python3.9/site-packages (from bokeh<4,>=3->hail) (6.1)\nRequirement already satisfied: pillow>=7.1.0 in /databricks/python3/lib/python3.9/site-packages (from bokeh<4,>=3->hail) (9.0.1)\nRequirement already satisfied: packaging>=16.8 in /databricks/python3/lib/python3.9/site-packages (from bokeh<4,>=3->hail) (21.3)\nRequirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /databricks/python3/lib/python3.9/site-packages (from boto3<2.0,>=1.17->hail) (0.5.0)\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /databricks/python3/lib/python3.9/site-packages (from boto3<2.0,>=1.17->hail) (0.10.0)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /databricks/python3/lib/python3.9/site-packages (from botocore<2.0,>=1.20->hail) (2.8.2)\nRequirement already satisfied: urllib3<1.27,>=1.25.4 in /databricks/python3/lib/python3.9/site-packages (from botocore<2.0,>=1.20->hail) (1.26.9)\nRequirement already satisfied: cffi>=1.12 in /databricks/python3/lib/python3.9/site-packages (from cryptography>=2.5->azure-identity<2,>=1.6.0->hail) (1.15.0)\nRequirement already satisfied: pycparser in /databricks/python3/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=2.5->azure-identity<2,>=1.6.0->hail) (2.21)\nCollecting wrapt<2,>=1.10\n  Downloading wrapt-1.15.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\nCollecting cachetools<6.0,>=2.0.0\n  Downloading cachetools-5.3.1-py3-none-any.whl (9.3 kB)\nCollecting pyasn1-modules>=0.2.1\n  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\nCollecting rsa<5,>=3.1.4\n  Downloading rsa-4.9-py3-none-any.whl (34 kB)\nCollecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5\n  Downloading google_api_core-2.11.1-py3-none-any.whl (120 kB)\nCollecting google-cloud-core<3.0dev,>=2.3.0\n  Downloading google_cloud_core-2.3.3-py2.py3-none-any.whl (29 kB)\nCollecting google-resumable-media>=2.3.2\n  Downloading google_resumable_media-2.5.0-py2.py3-none-any.whl (77 kB)\nCollecting googleapis-common-protos<2.0.dev0,>=1.56.2\n  Downloading googleapis_common_protos-1.60.0-py2.py3-none-any.whl (227 kB)\nCollecting google-crc32c<2.0dev,>=1.0\n  Downloading google_crc32c-1.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB)\nRequirement already satisfied: setuptools in /databricks/python3/lib/python3.9/site-packages (from hurry.filesize<1,>=0.9->hail) (61.2.0)\nRequirement already satisfied: MarkupSafe>=0.23 in /databricks/python3/lib/python3.9/site-packages (from Jinja2>=2.9->bokeh<4,>=3->hail) (2.0.1)\nCollecting PyJWT[crypto]<3,>=1.0.0\n  Downloading PyJWT-2.8.0-py3-none-any.whl (22 kB)\nCollecting portalocker<3,>=1.0\n  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\nCollecting requests-oauthlib>=0.5.0\n  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.9/site-packages (from msrest>=0.6.21->azure-mgmt-storage==20.1.0->hail) (2021.10.8)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /databricks/python3/lib/python3.9/site-packages (from packaging>=16.8->bokeh<4,>=3->hail) (3.0.4)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.9/site-packages (from pandas<3,>=2->hail) (2021.3)\nCollecting tzdata>=2022.1\n  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\nCollecting regex>=2022.3.15\n  Downloading regex-2023.6.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (769 kB)\nRequirement already satisfied: tenacity>=6.2.0 in /databricks/python3/lib/python3.9/site-packages (from plotly<6,>=5.5.0->hail) (8.0.1)\nCollecting pyasn1<0.6.0,>=0.4.6\n  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\nCollecting py4j==0.10.9.5\n  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.9/site-packages (from requests<3,>=2.25.1->hail) (3.3)\nCollecting oauthlib>=3.0.0\n  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /databricks/python3/lib/python3.9/site-packages (from typer<1,>=0.9.0->hail) (8.0.4)\nBuilding wheels for collected packages: avro, hurry.filesize, pyspark\n  Building wheel for avro (PEP 517): started\n  Building wheel for avro (PEP 517): finished with status 'done'\n  Created wheel for avro: filename=avro-1.11.2-py2.py3-none-any.whl size=119756 sha256=46c52f51dbe1eff1b77509a67015804ef16933996f503dfe352e7c82d21a8eae\n  Stored in directory: /root/.cache/pip/wheels/e3/a2/1e/5c1be0865f4170a89de34e0a798f32f674a7eaf63a93272c7f\n  Building wheel for hurry.filesize (setup.py): started\n  Building wheel for hurry.filesize (setup.py): finished with status 'done'\n  Created wheel for hurry.filesize: filename=hurry.filesize-0.9-py3-none-any.whl size=4132 sha256=1dfed9fe223f06cb0e007b94d4787472e4fd220c13d182eb50208458add497bd\n  Stored in directory: /root/.cache/pip/wheels/3c/97/5e/2475af1d4343e1d41becdfa497e764625ac3b226ac9299aeda\n  Building wheel for pyspark (setup.py): started\n  Building wheel for pyspark (setup.py): finished with status 'done'\n  Created wheel for pyspark: filename=pyspark-3.3.2-py2.py3-none-any.whl size=281824025 sha256=808b0d51c0b1b2dc48febdf709f11a46b067f5ac748cf3090e7f273c3532a969\n  Stored in directory: /root/.cache/pip/wheels/6c/e3/9b/0525ce8a69478916513509d43693511463c6468db0de237c86\nSuccessfully built avro hurry.filesize pyspark\nInstalling collected packages: pyasn1, rsa, PyJWT, pyasn1-modules, protobuf, cachetools, typing-extensions, oauthlib, googleapis-common-protos, google-auth, tzdata, requests-oauthlib, portalocker, multidict, msal, isodate, google-crc32c, google-api-core, frozenlist, azure-core, yarl, xyzservices, wrapt, regex, pyyaml, pycares, py4j, pandas, msrest, msal-extensions, google-resumable-media, google-cloud-core, contourpy, commonmark, azure-mgmt-core, azure-common, async-timeout, aiosignal, uvloop, typer, tabulate, sortedcontainers, rich, python-json-logger, pyspark, parsimonious, orjson, jproperties, janus, hurry.filesize, humanize, google-cloud-storage, dill, Deprecated, decorator, bokeh, azure-storage-blob, azure-mgmt-storage, azure-identity, avro, asyncinit, aiohttp, aiodns, hail\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 3.19.4\n    Not uninstalling protobuf at /databricks/python3/lib/python3.9/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-f8d2828a-4f3d-41b3-b96a-5cd6a20a018d\n    Can't uninstall 'protobuf'. No files were found to uninstall.\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing-extensions 4.1.1\n    Not uninstalling typing-extensions at /databricks/python3/lib/python3.9/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-f8d2828a-4f3d-41b3-b96a-5cd6a20a018d\n    Can't uninstall 'typing-extensions'. No files were found to uninstall.\n  Attempting uninstall: pandas\n    Found existing installation: pandas 1.4.2\n    Not uninstalling pandas at /databricks/python3/lib/python3.9/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-f8d2828a-4f3d-41b3-b96a-5cd6a20a018d\n    Can't uninstall 'pandas'. No files were found to uninstall.\n  Attempting uninstall: decorator\n    Found existing installation: decorator 5.1.1\n    Not uninstalling decorator at /databricks/python3/lib/python3.9/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-f8d2828a-4f3d-41b3-b96a-5cd6a20a018d\n    Can't uninstall 'decorator'. No files were found to uninstall.\nSuccessfully installed Deprecated-1.2.14 PyJWT-2.8.0 aiodns-2.0.0 aiohttp-3.8.5 aiosignal-1.3.1 async-timeout-4.0.2 asyncinit-0.2.4 avro-1.11.2 azure-common-1.1.28 azure-core-1.28.0 azure-identity-1.13.0 azure-mgmt-core-1.4.0 azure-mgmt-storage-20.1.0 azure-storage-blob-12.17.0 bokeh-3.2.1 cachetools-5.3.1 commonmark-0.9.1 contourpy-1.1.0 decorator-4.4.2 dill-0.3.7 frozenlist-1.4.0 google-api-core-2.11.1 google-auth-2.22.0 google-cloud-core-2.3.3 google-cloud-storage-2.10.0 google-crc32c-1.5.0 google-resumable-media-2.5.0 googleapis-common-protos-1.60.0 hail-0.2.120 humanize-1.1.0 hurry.filesize-0.9 isodate-0.6.1 janus-1.0.0 jproperties-2.1.1 msal-1.23.0 msal-extensions-1.0.0 msrest-0.7.1 multidict-6.0.4 oauthlib-3.2.2 orjson-3.9.2 pandas-2.0.3 parsimonious-0.10.0 portalocker-2.7.0 protobuf-3.20.2 py4j-0.10.9.5 pyasn1-0.5.0 pyasn1-modules-0.3.0 pycares-4.3.0 pyspark-3.3.2 python-json-logger-2.0.7 pyyaml-6.0.1 regex-2023.6.3 requests-oauthlib-1.3.1 rich-12.6.0 rsa-4.9 sortedcontainers-2.4.0 tabulate-0.9.0 typer-0.9.0 typing-extensions-4.7.1 tzdata-2023.3 uvloop-0.17.0 wrapt-1.15.0 xyzservices-2023.7.0 yarl-1.9.2\nPython interpreter will be restarted.\n"
     ]
    }
   ],
   "source": [
    "pip install hail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fe4f5373-edfa-4085-98af-2f781e8c58db",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import hail as hl\n",
    "hl.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "34737714-6870-4232-a2a9-54db679b4686",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "input_bam_path = '/dbfs/path/to/aligned_reads.bam'\n",
    "mt = hl.import_bam(input_bam_path, reference_genome='GRCh38')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "288c1fd7-86a2-418e-bbe4-317a5f85bf15",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mt_snps = mt.filter_rows(mt.alleles.is_snp())\n",
    "\n",
    "# Show SNPs (You can perform additional analyses or write the results to a file)\n",
    "mt_snps.rows().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dd812c2a-8088-48a4-9430-1aa6c23397e3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Filter the matrix table to keep only insertions\n",
    "mt_insertions = mt.filter_rows(mt.alleles.is_insertion())\n",
    "\n",
    "# Show insertions (You can perform additional analyses or write the results to a file)\n",
    "mt_insertions.rows().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5f255def-d244-4941-b71e-84761bb60f47",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mt_deletions = mt.filter_rows(mt.alleles.is_deletion())\n",
    "\n",
    "# Show deletions (You can perform additional analyses or write the results to a file)\n",
    "mt_deletions.rows().show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7ca60da9-e1a6-4b7d-8938-46c7a841e4eb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Call structural variations using hl.lumpy\n",
    "lumpy_result = hl.lumpy(mt)\n",
    "\n",
    "# Show structural variations (You can perform additional analyses or write the results to a file)\n",
    "lumpy_result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a4d3b5ea-c2e6-4ae5-8746-9a39e9ee091e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Gene expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9dbfbfea-eefd-4455-81c0-abc4ba9eefb0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects import pandas2ri\n",
    "\n",
    "# Install the required R packages (DESeq2 and edgeR) using rpy2\n",
    "r_install_packages = \"\"\"\n",
    "install.packages(\"DESeq2\")\n",
    "install.packages(\"edgeR\")\n",
    "\"\"\"\n",
    "\n",
    "robjects.r(r_install_packages)\n",
    "\n",
    "def differential_gene_expression_analysis(data, condition_col, method='DESeq2'):\n",
    "    \"\"\"\n",
    "    Perform differential gene expression analysis using DESeq2 or edgeR.\n",
    "\n",
    "    Parameters:\n",
    "        data (pandas.DataFrame): DataFrame containing gene expression data. Rows represent genes, columns represent samples.\n",
    "        condition_col (str): The name of the column in the DataFrame that represents the experimental condition or group for each sample.\n",
    "        method (str): The method to use for differential gene expression analysis. Options: 'DESeq2' (default) or 'edgeR'.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame containing the differential gene expression results.\n",
    "    \"\"\"\n",
    "    # Ensure that rpy2 will convert pandas DataFrame to R DataFrame\n",
    "    pandas2ri.activate()\n",
    "\n",
    "    # Load the required R packages (DESeq2 and edgeR)\n",
    "    robjects.r(f\"library({method})\")\n",
    "\n",
    "    # Convert the pandas DataFrame to an R DataFrame\n",
    "    r_data = pandas2ri.py2ri(data)\n",
    "\n",
    "    # Perform normalization and differential expression analysis\n",
    "    if method == 'DESeq2':\n",
    "        # Using DESeq2 for differential expression analysis\n",
    "        robjects.r(f\"dds <- DESeqDataSetFromMatrix(countData=r_data, colData=as.data.frame(r_data['{condition_col}']), design=~{condition_col})\")\n",
    "        robjects.r(\"dds <- DESeq(dds)\")\n",
    "        result = robjects.r(\"res <- results(dds)\")\n",
    "\n",
    "    elif method == 'edgeR':\n",
    "        # Using edgeR for differential expression analysis\n",
    "        robjects.r(f\"y <- DGEList(counts=r_data, group=as.factor(r_data['{condition_col}']))\")\n",
    "        robjects.r(\"y <- calcNormFactors(y)\")\n",
    "        robjects.r(\"design <- model.matrix(~as.factor(r_data['{condition_col}']))\")\n",
    "        robjects.r(\"y <- estimateDisp(y, design)\")\n",
    "        robjects.r(\"fit <- glmFit(y, design)\")\n",
    "        result = robjects.r(\"res <- glmLRT(fit)\")\n",
    "\n",
    "    # Convert the R DataFrame result back to a pandas DataFrame\n",
    "    result_df = pandas2ri.ri2py_dataframe(result)\n",
    "\n",
    "    return result_df\n",
    "Example usage:\n",
    "\n",
    "\n",
    "# Assuming you have loaded your gene expression data into a pandas DataFrame 'gene_expression_df'\n",
    "\n",
    "# Perform differential gene expression analysis using DESeq2\n",
    "deseq2_results = differential_gene_expression_analysis(gene_expression_df, condition_col='Condition', method='DESeq2')\n",
    "\n",
    "# Perform differential gene expression analysis using edgeR\n",
    "edger_results = differential_gene_expression_analysis(gene_expression_df, condition_col='Condition', method='edgeR')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bb71fcd0-e82d-4331-a6ff-022864ec20b4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Perform differential gene expression analysis using DESeq2\n",
    "deseq2_results = differential_gene_expression_analysis(gene_expression_df, condition_col='Condition', method='DESeq2')\n",
    "\n",
    "# Perform differential gene expression analysis using edgeR\n",
    "edger_results = differential_gene_expression_analysis(gene_expression_df, condition_col='Condition', method='edgeR')"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "NGS_CANCER_PROFILING_final_4th",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
